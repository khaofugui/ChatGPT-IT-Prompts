{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fecb22ac",
   "metadata": {},
   "source": [
    "## 实验：ChatGPT API 交互编程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c954b104",
   "metadata": {},
   "source": [
    "### 本地环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed8c7067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.family'] = 'sans-serif'    # 用来正常显示中文\n",
    "plt.rcParams['font.sans-serif'] = 'SimHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False   # 设置正常显示符号\n",
    "\n",
    "# 设置输入输出路径\n",
    "import os\n",
    "base_path = os.environ.get(\"BASE_PATH\",'../data/')\n",
    "data_path = os.path.join(base_path + \"lab4/ml-latest-small/\")\n",
    "result_path = \"result/\"\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "# 忽略第三方支援库更新兼容性提示\n",
    "import warnings\n",
    "warnings.simplefilter('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dd349d",
   "metadata": {},
   "source": [
    "### 指令格式\n",
    "\n",
    "请作为一个软件开发工程师，我希望将 ChatGPT API 集成到我的程序中，通过对话框实现与 ChatGPT API  交互式会话，我希望采用 text-davinci-003 模型，请提供对应的 Python 代码，并加入注释。我的 OPENAI_API_KEY 是：**<font color=\"#0000dd\">[OPENAI_API_KEY]**\n",
    "\n",
    "### 指令示例\n",
    "\n",
    "请作为一个软件开发工程师，我希望将 ChatGPT API 集成到我的程序中，通过对话框实现与 ChatGPT API  交互式会话，我希望采用 text-davinci-003 模型，请提供对应的 Python 代码，并加入注释。我的 OPENAI_API_KEY 是：`[ABC01234556709]`\n",
    "\n",
    "<img src=\"./img/4-3.png\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b8c90f",
   "metadata": {},
   "source": [
    "### ChatGPT 代码测试\n",
    "\n",
    "**注意：需要提前安装 OpenAI SDK** ——\n",
    "\n",
    "注意：截止至 2023 年 2 月，OpenAI 的 API_KEY 暂时无法调用 ChatGPT 模型，我们这里临时使用 GPT-3 的 `text-davinci-003` 模型演示。请勿被网上所谓私有化部署 ChatGPT、微信集成 ChatGPT 的文章误导。目前，使用 ChatGPT 暂时只能通过 Web 页面调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e916b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e668a92d",
   "metadata": {},
   "source": [
    "**注意：此处需要替换 `ABC01234556709` 为你自己的 OPENAI APIKEY**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f24641b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始聊天！输入'quit'退出程序。\n",
      "你: 请简单介绍一下你自己\n",
      "ChatGPT: 我叫XXX，今年XX岁，来自XX省XX市，目前就读于XX大学，专业是XX。我喜欢阅读、运动和旅游，乐于助人，乐观开朗、积极向上。未来，我想做一名有能力有担当的人，为社会做出贡献。\n",
      "你: quit\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import time\n",
    "\n",
    "# 将您的 API 密钥放在这里\n",
    "openai.api_key = \"ABC01234556709\"\n",
    "\n",
    "# 设置模型和引擎ID\n",
    "model_engine = \"text-davinci-003\"\n",
    "\n",
    "# 向API发送请求，返回响应\n",
    "def generate_response(prompt):\n",
    "    \"\"\"\n",
    "    向OpenAI API发送请求，并返回API响应。\n",
    "\n",
    "    参数:\n",
    "    prompt (str): 用户在对话框中输入的文本。\n",
    "\n",
    "    返回:\n",
    "    str: ChatGPT API生成的文本响应。\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=model_engine,  # 要使用的模型引擎 ID。\n",
    "        prompt=prompt,  # API请求的文本提示。\n",
    "        max_tokens=1024,  # 返回的响应中最大的token数。\n",
    "        n=1,  # 返回响应的数量。\n",
    "        stop=None,  # 在响应中要停止生成文本的字符串。\n",
    "        temperature=0.5,  # 用于控制响应的“创造性”参数。\n",
    "    )\n",
    "    # 返回生成的文本响应，去除前后的空格。\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# 在命令行中运行对话\n",
    "def start_chat():\n",
    "    \"\"\"\n",
    "    用于命令行聊天交互的入口点。\n",
    "\n",
    "    用户输入文本，API生成响应并在控制台输出。\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"开始聊天！输入'quit'退出程序。\")\n",
    "    while True:\n",
    "        # 获取用户输入。\n",
    "        prompt = input(\"你: \")\n",
    "        # 如果用户输入'quit'，退出程序。\n",
    "        if prompt.lower() == \"quit\":\n",
    "            break\n",
    "        # 向API发送请求，等待响应。\n",
    "        response = generate_response(prompt)\n",
    "        # 输出生成的响应文本。\n",
    "        print(\"ChatGPT: \" + response)\n",
    "        # 等待一会，以便人类用户能够阅读响应文本。\n",
    "        time.sleep(0.5)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "225px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
